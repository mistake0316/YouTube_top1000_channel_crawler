# -*- coding: utf-8 -*-
"""youtube_top1000_crawler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ln6ffbUaoe9DrvgsugoWiKbmC4RG7sv0
"""

# !pip install beautifulsoup4 requests

import requests
import bs4
from IPython import display
import pandas as pd
from multiprocessing import Pool

def get_page(i=1):
  assert isinstance(i, int) and i >= 1 and i <= 20
  url = f"https://hypeauditor.com/top-youtube/?p={i}"
  resp = requests.get(url)
  soup = bs4.BeautifulSoup(resp.text, "html.parser")

  def select_and_callbacks(
    selector,
    callbacks = [
      lambda elem : elem.encode_contents().decode()
    ]
  ):
    ptr = soup.select(selector)
    if not isinstance(callbacks, list):
      callbacks = [callbacks]
      
    for fun in callbacks:
      ptr = [
        fun(elem) for elem in ptr
      ]
    return ptr
  
  ranks = select_and_callbacks("div.row-cell.rank > span")
  names = select_and_callbacks("div.contributor__name > div")
  followers = select_and_callbacks("div.row-cell.subscribers")
  country = select_and_callbacks("div.row-cell.audience")
  views = select_and_callbacks("div.row-cell.avg-views")
  likes = select_and_callbacks("div.row-cell.avg-likes")

  links = select_and_callbacks(
    "a.contributor-link",
    lambda elem:elem["href"]
  )
  categories = select_and_callbacks(
    "div.row-cell.category",
    lambda subElem: [
      elem.encode_contents().decode()
      for elem in subElem.select("div.tag__content")
    ]
  )

  return pd.DataFrame(
    dict(
      ranks=ranks,
      names=names,
      links=likes,
      categories=categories,
      followers=followers,
      country=country,
      views=views,
      likes=likes
    )
  ).set_index("ranks")

# Commented out IPython magic to ensure Python compatibility.
# %%time 
# # sometime it will have error
# with Pool(20) as p:
#   table = pd.concat(
#     p.map(get_page, range(1,21))
#   )

table

table.to_csv("top1000.csv", sep="\t")